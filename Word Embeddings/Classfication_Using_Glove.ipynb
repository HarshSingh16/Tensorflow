{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classfication_Using_Glove.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "RPDG82YD7KnB",
        "colab_type": "code",
        "outputId": "0e3097ec-cae9-43a8-aa13-e94c31c58bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "cell_type": "code",
      "source": [
        "#Classfication using GLove\n",
        "#Getting the data\n",
        "!wget https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-train-all-terms.txt"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-11 07:10:12--  https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-train-all-terms.txt\n",
            "Resolving www.cs.umb.edu (www.cs.umb.edu)... 158.121.106.224\n",
            "Connecting to www.cs.umb.edu (www.cs.umb.edu)|158.121.106.224|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3354424 (3.2M) [text/plain]\n",
            "Saving to: ‘r8-train-all-terms.txt.4’\n",
            "\n",
            "r8-train-all-terms. 100%[===================>]   3.20M  7.48MB/s    in 0.4s    \n",
            "\n",
            "2019-03-11 07:10:12 (7.48 MB/s) - ‘r8-train-all-terms.txt.4’ saved [3354424/3354424]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OapylLUSdven",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADRQeXm-7aNZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(\"r8-train-all-terms.txt\",sep =\"\\t\",header=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oWmxnftJ-cTo",
        "colab_type": "code",
        "outputId": "a60ae1ac-fbe7-4372-af63-8db7c1ff2943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-test-all-terms.txt"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-11 07:10:13--  https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-test-all-terms.txt\n",
            "Resolving www.cs.umb.edu (www.cs.umb.edu)... 158.121.106.224\n",
            "Connecting to www.cs.umb.edu (www.cs.umb.edu)|158.121.106.224|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1195261 (1.1M) [text/plain]\n",
            "Saving to: ‘r8-test-all-terms.txt.4’\n",
            "\n",
            "r8-test-all-terms.t 100%[===================>]   1.14M  4.71MB/s    in 0.2s    \n",
            "\n",
            "2019-03-11 07:10:14 (4.71 MB/s) - ‘r8-test-all-terms.txt.4’ saved [1195261/1195261]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OfMqNnt_-pzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test=pd.read_csv(\"r8-test-all-terms.txt\",sep =\"\\t\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "keUlrXM1dSDj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train.columns = ['label', 'content']\n",
        "\n",
        "test.columns = ['label', 'content']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmRxkRA1AwCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Glove_Vectorizer:\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    # load in pre-trained word vectors\n",
        "\n",
        "    print('Loading word vectors...')\n",
        "\n",
        "    word2vec = {}\n",
        "\n",
        "    embedding = []\n",
        "\n",
        "    idx2word = []\n",
        "\n",
        "    with open('glove.6B.50d.txt') as f:\n",
        "\n",
        "      # is just a space-separated text file in the format:\n",
        "\n",
        "      # word vec[0] vec[1] vec[2] ...\n",
        "\n",
        "      for line in f:\n",
        "\n",
        "        values = line.split()\n",
        "\n",
        "        word = values[0]\n",
        "\n",
        "        vec = np.asarray(values[1:], dtype='float32')\n",
        "\n",
        "        word2vec[word] = vec\n",
        "\n",
        "        embedding.append(vec)\n",
        "\n",
        "        idx2word.append(word)\n",
        "\n",
        "    print('Found %s word vectors.' % len(word2vec))\n",
        "\n",
        "\n",
        "\n",
        "    # save for later\n",
        "\n",
        "    self.word2vec = word2vec\n",
        "\n",
        "    self.embedding = np.array(embedding)\n",
        "\n",
        "    self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
        "\n",
        "    self.V, self.D = self.embedding.shape\n",
        "\n",
        "\n",
        "\n",
        "  def fit(self, data):\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "  def transform(self, data):\n",
        "\n",
        "    X = np.zeros((len(data), self.D))\n",
        "\n",
        "    n = 0\n",
        "\n",
        "    emptycount = 0\n",
        "\n",
        "    for sentence in data:\n",
        "\n",
        "      tokens = sentence.lower().split()\n",
        "\n",
        "      vecs = []\n",
        "\n",
        "      for word in tokens:\n",
        "\n",
        "        if word in self.word2vec:\n",
        "\n",
        "          vec = self.word2vec[word]\n",
        "\n",
        "          vecs.append(vec)\n",
        "\n",
        "      if len(vecs) > 0:\n",
        "\n",
        "        vecs = np.array(vecs)\n",
        "\n",
        "        X[n] = vecs.mean(axis=0)\n",
        "\n",
        "      else:\n",
        "\n",
        "        emptycount += 1\n",
        "\n",
        "      n += 1\n",
        "\n",
        "    print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "  def fit_transform(self, data):\n",
        "\n",
        "    self.fit(data)\n",
        "\n",
        "    return self.transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UoNR5YUlW5qZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "39d9f7ee-c412-48d5-ad50-1d81e440c9a9"
      },
      "cell_type": "code",
      "source": [
        "vectorizer = Glove_Vectorizer()\n",
        "\n",
        "# vectorizer = Word2VecVectorizer()\n",
        "\n",
        "Xtrain = vectorizer.fit_transform(train.content)\n",
        "\n",
        "Ytrain = train.label\n",
        "\n",
        "\n",
        "\n",
        "Xtest = vectorizer.transform(test.content)\n",
        "\n",
        "Ytest = test.label"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n",
            "Numer of samples with no words found: 0 / 5485\n",
            "Numer of samples with no words found: 0 / 2189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0PGWt8AMdghM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c89d7cdd-951e-44c5-b82b-13cb6af0a450"
      },
      "cell_type": "code",
      "source": [
        "# create the model, train it, print scores\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "\n",
        "model.fit(Xtrain, Ytrain)\n",
        "\n",
        "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
        "\n",
        "print(\"test score:\", model.score(Xtest, Ytest))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train score: 0.9992707383773929\n",
            "test score: 0.9346733668341709\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}